{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/felixquinque/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/felixquinque/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nlp_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"There is a very fluffy and round elephant shrew running around the desert! And a second sentence\"\n",
    "text2 = \"A round Manatee is swimming through the river, enjoying it's food\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_clean,_ = nlp_utils.process_text(text1, remove_punctuation=True, split_sentences=False)\n",
    "text2_clean,_ = nlp_utils.process_text(text2, remove_punctuation=True, split_sentences=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sortedcontainers import SortedDict\n",
    "\n",
    "\n",
    "def create_corpus(texts: str, overlap_only: bool = False):\n",
    "    \"\"\" Creates the corpus to create Bag of Word embeddings\n",
    "\n",
    "    Args:\n",
    "        texts (str): list of texts for which to create the embeddings\n",
    "        overlap_only (bool, optional): Whether to create an overlap only. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        _type_: a list of words representing the corpus\n",
    "    \"\"\"\n",
    "    if overlap_only:\n",
    "        all_words = [word.lower() for text in texts for word in text]\n",
    "        words = dict.fromkeys(all_words,0)\n",
    "        for word in all_words:\n",
    "            words[word] += 1\n",
    "        corpus = []\n",
    "        for word in all_words:\n",
    "            if words[word] > 1:\n",
    "                corpus.append(word)\n",
    "        return corpus\n",
    "    \n",
    "    else:\n",
    "        corpus = [word.lower() for text in texts for word in text]\n",
    "        return np.unique(corpus)\n",
    "    \n",
    "\n",
    "def create_bow_encoding(texts: list, words: list) -> list[dict]:\n",
    "    \"\"\"\n",
    "    texts (list[list[str]]): a list of texts for which we want to create the embeddings. Each text is a list of words\n",
    "    words (list[str]): a list of all words for which we want to create the embeddings\n",
    "    \n",
    "    returns a list of dictionaries, where each dictionary corresponds to one text\n",
    "    \"\"\"\n",
    "    if not isinstance(texts[0], list):\n",
    "        texts = [texts]\n",
    "    words = SortedDict.fromkeys(words,0)\n",
    "    all_counts = []\n",
    "    for text in texts:\n",
    "        temp_words = copy.deepcopy(words)\n",
    "        for word in text:\n",
    "            try:\n",
    "                temp_words[word.lower()] += 1 # if the word is not in the original dictionary ignore it\n",
    "            except:\n",
    "                pass\n",
    "        all_counts.append(temp_words)\n",
    "    return all_counts\n",
    "\n",
    "def flatten(S: list) -> list:\n",
    "    \"\"\" Flatten a nested list into a single (flat) list\n",
    "\n",
    "    Args:\n",
    "        S (list): nested list to flatten\n",
    "\n",
    "    Returns:\n",
    "        list: a list containing the elements of the nested list without the nesting.\n",
    "    \"\"\"\n",
    "    if S == []:\n",
    "        return S\n",
    "    if isinstance(S[0], list):\n",
    "        return flatten(S[0]) + flatten(S[1:])\n",
    "    return S[:1] + flatten(S[1:])\n",
    "\n",
    "def make_bow(texts: str, overlap_only: bool = False) -> tuple(list[dict], list[str]):\n",
    "    \"\"\" Takes in a list of texts and returns the bag of word encoding of the texts. \n",
    "\n",
    "    Args:\n",
    "        texts list[list[str]]: A list containing multiple texts which are each tokenized into their words\n",
    "\n",
    "    Returns:\n",
    "        tuple(list[dict], list[str]): returns a list of dictionaries (the bow encodings for each text) and a list of words that make up the corpus\n",
    "    \"\"\"\n",
    "    corpus = create_corpus(texts, overlap_only=overlap_only)\n",
    "    return create_bow_encoding(texts, corpus), corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SortedDict({'a': 2, 'and': 2, 'is': 1, 'round': 1, 'the': 1}),\n",
       " SortedDict({'a': 1, 'and': 0, 'is': 1, 'round': 1, 'the': 1})]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [text1_clean, text2_clean]\n",
    "\n",
    "make_bow(texts, overlap_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SortedDict({'a': 2, 'and': 2, 'is': 1, 'round': 1, 'the': 1}),\n",
       " SortedDict({'a': 1, 'and': 0, 'is': 1, 'round': 1, 'the': 1})]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp = create_corpus(texts, overlap_only=True)\n",
    "create_bow(texts, corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SortedDict({'A': 0, 'And': 1, 'Manatee': 0, 'There': 1, 'a': 2, 'and': 1, 'around': 1, 'desert': 1, 'elephant': 1, 'enjoying': 0, 'fluffy': 1, 'food': 0, 'is': 1, 'its': 0, 'river': 0, 'round': 1, 'running': 1, 'second': 1, 'sentence': 1, 'shrew': 1, 'swimming': 0, 'the': 1, 'through': 0, 'very': 1}),\n",
       " SortedDict({'A': 1, 'And': 0, 'Manatee': 1, 'There': 0, 'a': 0, 'and': 0, 'around': 0, 'desert': 0, 'elephant': 0, 'enjoying': 1, 'fluffy': 0, 'food': 1, 'is': 1, 'its': 1, 'river': 1, 'round': 1, 'running': 0, 'second': 0, 'sentence': 0, 'shrew': 0, 'swimming': 1, 'the': 1, 'through': 1, 'very': 0})]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SortedDict({'A': 1, 'And': 1, 'Manatee': 1, 'There': 1, 'a': 2, 'and': 1, 'around': 1, 'desert': 1, 'elephant': 1, 'enjoying': 1, 'fluffy': 1, 'food': 1, 'is': 2, 'its': 1, 'river': 1, 'round': 2, 'running': 1, 'second': 1, 'sentence': 1, 'shrew': 1, 'swimming': 1, 'the': 2, 'through': 1, 'very': 1})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SortedDict({'alpha': 2, 'beta': 1})\n"
     ]
    }
   ],
   "source": [
    "dic = SortedDict()\n",
    "dic[\"beta\"] = 1\n",
    "dic[\"alpha\"] = 2\n",
    "\n",
    "print(dic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
